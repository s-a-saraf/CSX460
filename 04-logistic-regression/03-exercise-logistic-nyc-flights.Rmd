---
title: "NYCFlights: Arrival Delay Logictic Model"
author: "Snehal A. Saraf"
date: "23 Oct 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(psych)
library(readr)
library(magrittr)
library(lubridate)
library(stringr)
library(dplyr)
```


## Logsitic and Inverse Logistic Transformation 

# Write an R function for the logistic function. The function should accept a `numeric` vector with values `[-Inf,Inf]` and produce a numeric vector in the the range `[0,1]`.

``` {r "Logistic function"}
    logfunc <- function(x) {
        y1 <- -1 * x
        y2 <- exp(y1) 
        y3 <- 1 + y2
        y4 <- 1/y3
        return(y4)
    }

```

# Plot the logistic function from  `[-10,10]`
``` {r "Plot logistic function from -10 to 10"}
    x <- c(-10:10)
    res <- logfunc(x)
    ggplot(data = data.frame(x, res), aes(x, res)) + geom_line()
```

# Write a R function for the inverse logistic function. The function should accept a `numeric` vector with values `[0,1]` and prodcuce a numeric vector in the range `[-Inf,Inf]`

``` {r "Inverse logistic function"}
   revlogfunc <- function(y) {
     x1 <- (1/y)
     x2 <- x1-1
     x3 <- log(x2)
     x4 <- -1 * x3
     return(x4)
   }
```

# Plot the Inverse Logistic function from `[0,1]`
``` {r "Plot Inverse Logistic function from 0-1"}
    # Take res in this case
    res2 <- revlogfunc(res)
    ggplot(data = data.frame(res, res2), aes(res, res2)) + geom_line()
```

**Hint:** For plotting curves see `?graphics::curve` or `?ggplot2::stat_function`

```{r "Logistic and Inverse Logistic" }

```


# NYCFlights Model

Using the rectangular data that you created from assignment and following the *Predicting Medical Expenses* example from the text (*MLwR*), create a model for arr_delay >= 15 minutes. Follow *MLwR* structure   for building a model. Describe/Explain each of the steps and show all work in codeblocks below.

KNIT YOUR DOCUMENT AS *HTML* AND SUBMIT IT AND THE `Rmd` file.   

## Step 1: Collect Data 

```{r "Step 1: Collect Data" }
load("~/csx460/CSX460/02-fundamentals/data/ex2.RData")
setwd("~/csx460/CSX460/02-fundamentals/data/")
yxlo <- YX

```

## Step 2: Explore and Prep The Data


One of the things not done in the MLwR text is a pairwise comparison between the response and each of the predictors. Make sure to do this; this is often very illustrative of the relationship between that predictor and the response. This can be done with `pairs` or `psych::panel.pairs`


```{r "Step 2: Explore and Prep The Data" }
# Naive model

# Study the table given and cherry pick the important features

y <- "arr_delay"
xs <- c(
    'month','dep_delay','carrier','air_time','distance'
   ,'year.y','type','engine'
   ,'wind_dir','wind_speed','wind_gust','precip','pressure','visib'
   ,'lat.x','lon.x','lat.y','lon.y'
)

yxlo <- YX[, c(y, xs)]
yxlo$delayed <- ifelse(yxlo$arr_delay >= 15, 1, 0)
 
# Remove the param "arr_delay" since it is replaced with "delayed"
yxlo <- yxlo[, !(names(yxlo) %in% c("arr_delay"))]
ggplot(data = yxlo, aes(delayed)) + geom_histogram()

# Get the feature with a single value for all egs. < o/p year.x tz.x >
# yxlo %>% sapply(. %>% unique %>% length)
# summary(yxlo$year.x)
# summary(yxlo$tz.x)
# summary(yxlo$dst.x)

# Remove single valued features
# yxlo <- yxlo[, !(names(yxlo) %in% c("year.x", "tz.x", "dst.x"))]

# Get the no of NA's in each feature
yxlo %>% sapply(. %>% is.na %>% sum)
library("Amelia")
missmap(yxlo)

# speed has lots of NA and can be deleted. Same with manufacturer, manuf, model, type, seats.
yxlo <- yxlo[, !(names(yxlo) %in% c("speed"))]

# Replace the NA's in each column.
for(i in 1:ncol(yxlo)){
#  if (yxlo(, i) %>% sapply(., is.numeric))
  yxlo[is.na(yxlo[,i]), i] <- mean(yxlo[,i], na.rm = TRUE)
}

# Divide the data into training, cv and test sets.

# Use caret lib's createFolds() to create 10 folds. Ideally, we would want to run the model on 
# each of the fold as test data. Each fold holds random set of rows.
library("caret")
#folds <- createFolds(yxlo$delayed, k = 10)
#str(folds)
```

## Step 3:  Train The Model

```{r "Step 3: Train The Model" }



# Ideally we have to loop using each fold [1 ... 10] as a test set and remaining folds as training set.
# Fold02, 03, 04 ... 10 in a loop

# Divide the test set into two parts CV & test randomly.
#rand <- order(runif(nrow(folds$Fold01)))

#test_set <- yxlo[rand[1:(nrow(folds$Fold01)/2)]]
#cv_set <- yxlo[rand[(nrow(folds$Fold01)/2)+1 : (nrow(folds$Fold01))]]

#train_set <- yxlo[-folds$Fold01] 

partition <- sample(1:nrow(yxlo), nrow(yxlo)*0.75, replace = FALSE)

train_set <- yxlo[partition, ]
cv_set <- yxlo[-partition, ]

train_set %>% sapply(. %>% unique %>% length)
#sampled_set <- sample_n(train_set, 15000, replace = FALSE)
logisticmodel <- glm(delayed ~ ., data = train_set, family = "binomial")
#head(logisticmodel)
```

## Step 4: Evaluate Performance

#Think about some of the tools that you have for evaluating performance.  Choose one and articulate why you have chosen it.

```{r "Step 4: Evaluate Performance" }

# Run the model on the cv_set
#cv_set <- sample_n(yxlo, 90000, replace = FALSE)
predictedRes <- predict(logisticmodel, cv_set, type = "response")

# Create a new table with "Actual OP"  "Predicted OP" for the cv_set
predictTable <- data.frame(predict_type = predictedRes, actual_type = cv_set$delayed)
# Apply ROC to get the threshold
library(pROC)
analysis <- roc(response=predictTable$actual_type, predictor=predictTable$predict_type)
e <- cbind(analysis$thresholds,analysis$sensitivities+analysis$specificities)
opt_t <- subset(e,e[,2]==max(e[,2]))[,1]

#Plot ROC Curve
plot(1-analysis$specificities,analysis$sensitivities,type="l",
ylab="Sensitiviy",xlab="1-Specificity",col="black",lwd=2,
main = "ROC Curve for Simulated Data")
abline(a=0,b=1)
abline(v = opt_t) #add optimal t to ROC curve
opt_t #print t

# O/p of above ROC intersection of sensitivity and specificity
predict_threshold <- 0.2639371

# Create a new table with "Actual OP"  "Predicted OP" for the cv_set
predictTable$predict_type[which(predictTable$predict_type < predict_threshold)] <- 0
predictTable$predict_type[which(predictTable$predict_type >= predict_threshold)] <- 1

# Create the confusion Matrix
library(caret)
confusionMat <- confusionMatrix(predictTable$predict_type, predictTable$actual_type, positive = "1")

# Get the sensitivity < True Positive Ratio >
sensi <- sensitivity(predictTable$predict_type, predictTable$actual_type, positive=1)

# Get the specificity < True Negative Ratio >
#speci <- specificity(predictTable$predict_type, predictTable$actual_type, negative=0)


```

## Step 5: Improve Performance 

Show some steps for improving model performance.

```{r "Step 5: Improve Performance" }
# Based on specificity, sensitivity, precision and recall values, we can think of
# using certain new combination values etc
```


# Question:

Is this a good model?  (Write your answer here.)


# PART B:

Your model should be good at explaining tardiness. Now, assume that your job is to predict arrival delays a month in advance. You can no longer use all the features in your model. Retrain your model using only features that will be *known* only a month in advance of the departure time.  Show all steps as above.

```{r "Step B.1 - B.2 Collect / Prep data - dep_delay etc not known"}
y <- "arr_delay"
xs <- c(
    'month','carrier','air_time','distance'
   ,'year.y','type','engine'
   ,'wind_dir','wind_speed','wind_gust','precip','pressure','visib'
   ,'lat.x','lon.x','lat.y','lon.y'
)


yxlo <- YX[, c(y, xs)]
yxlo$delayed <- ifelse(yxlo$arr_delay >= 15, 1, 0)
#Remove arr_delay
yxlo <- yxlo[, !(names(yxlo) %in% c("arr_delay"))] 

ggplot(data = yxlo, aes(delayed)) + geom_histogram()

yxlo %>% sapply(. %>% is.na %>% sum)
library("Amelia")
missmap(yxlo)

# speed has lots of NA and can be deleted. Same with manufacturer, manuf, model, type, seats.
yxlo <- yxlo[, !(names(yxlo) %in% c("speed"))]

# Replace the NA's in each column.
for(i in 1:ncol(yxlo)){
#  if (yxlo(, i) %>% sapply(., is.numeric))
  yxlo[is.na(yxlo[,i]), i] <- mean(yxlo[,i], na.rm = TRUE)
}

```

```{r "Step B.3: Train The Model" }

partition <- sample(1:nrow(yxlo), nrow(yxlo)*0.75, replace = FALSE)

train_set <- yxlo[partition, ]
cv_set <- yxlo[-partition, ]

train_set %>% sapply(. %>% unique %>% length)
#sampled_set <- sample_n(train_set, 15000, replace = FALSE)
logisticmodel <- glm(delayed ~ ., data = train_set, family = "binomial")
#head(logisticmodel)

```


```{r "Step B.4: Evaluate Performance" }

# Run the model on the cv_set
#cv_set <- sample_n(yxlo, 90000, replace = FALSE)
predictedRes <- predict(logisticmodel, cv_set, type = "response")

# Create a new table with "Actual OP"  "Predicted OP" for the cv_set
predictTable <- data.frame(predict_type = predictedRes, actual_type = cv_set$delayed)
# Apply ROC to get the threshold
library(pROC)
analysis <- roc(response=predictTable$actual_type, predictor=predictTable$predict_type)
e <- cbind(analysis$thresholds,analysis$sensitivities+analysis$specificities)
opt_t <- subset(e,e[,2]==max(e[,2]))[,1]

#Plot ROC Curve
plot(1-analysis$specificities,analysis$sensitivities,type="l",
ylab="Sensitiviy",xlab="1-Specificity",col="black",lwd=2,
main = "ROC Curve for Simulated Data")
abline(a=0,b=1)
abline(v = opt_t) #add optimal t to ROC curve
opt_t #print t

# O/p of above ROC intersection of sensitivity and specificity
predict_threshold <- 0.2639371

# Create a new table with "Actual OP"  "Predicted OP" for the cv_set
predictTable$predict_type[which(predictTable$predict_type < predict_threshold)] <- 0
predictTable$predict_type[which(predictTable$predict_type >= predict_threshold)] <- 1

# Create the confusion Matrix
library(caret)
confusionMat <- confusionMatrix(predictTable$predict_type, predictTable$actual_type, positive = "1")

# Get the sensitivity < True Positive Ratio >
#sensi <- sensitivity(predictTable$predict_type, predictTable$actual_type, positive=1)

# Get the specificity < True Negative Ratio >
#speci <- specificity(predictTable$predict_type, predictTable$actual_type, negative=0)


```
